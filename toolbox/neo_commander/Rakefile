# -- usage: rake help

require "timeout"
require "fileutils"

# -- first global
@suite_root						= File.expand_path "#{File.dirname(__FILE__)}/.."						
@pfix									 = 'SADO_'

# -- global vars
task :default => [:run]
@chain                 	= []
@tasks_retried_counter 	= 0
@executed_tasks        	= 0
@current_task 				 	= 0


# -- last global 
@reports_dir           	= ENV["#{@pfix}REPORTS"].nil? ? "/sado_reports" : ENV["#{@pfix}REPORTS"]
@definition_hash 			 	= { }
@task_hash 							= { }

#
# -- the following vars control the behavior of running tests
#@task_types = {"ruby" => "RubyTask" , "WRTask"]
@task_config = {
   'output_on'                => true,
   'test_retry'               => false,
   'test_exit_status_passed'  => "PASSED", 		#1 example, 0 failures
   'test_exit_status_failed'  => "FAILED",
   'test_exit_status_skipped' => "SKIPPED",
   'reports_dir'              => @reports_dir
}

def read_yaml_file(file)
	if File.exist?(file)
		return YAML::load(File.read(file))
	end
	raise "-- ERROR: file doesn't exist: " + file
end

# -- prepare reports_dir
def prepare_reports_dir
   FileUtils.rm_r(@task_config['reports_dir']) if File.directory?(@task_config['reports_dir'])
   FileUtils.mkdir_p(@task_config['reports_dir'])
end

# -- our own each method yielding each test in the @tests array
def each
   @chain.each { |t| yield t }
end

def read_all_yaml
	@definition_hash 			 	= read_yaml_file(@suite_root+"/neocommander/lib/definitions.yaml")
	@task_hash 							= read_yaml_file(@suite_root+"/home/profiles/tasklist.yaml")
end

def prepare_taskchain
	@chain = TaskChain.new()
	@task_hash.each do |key, value|
		if key == "commander"
			@chain.set_chainname(value)
		else
			if key == "transpose"
				@chain.add_traspose(key, value)
			else
				@chain.add_task(key, value)
			end
		end
	end
end

# -- run all tests
desc "-- run all tests..."
task :run do
	# -- first, let's setup/cleanup reports_dir
	prepare_reports_dir
	
	# -- populate the profile data
	read_all_yaml
	
	# -- now, build the test toolchain from profile and task test files
	prepare_taskchain
	tStart = Time.now
	# -- let's run each test now
	each { |t|
    begin
      t.execute_task
      # -- do we run test more than once if it failed first time ?
      if (t.exit_status == @task_config['test_exit_status_failed']) and (@task_config['test_retry'])
        puts("-- first attempt failed, will try again...")
        t.validate
        @tests_retried_counter += 1
      end
		rescue => e
			puts "-- ERROR: " + e.inspect
			puts "   (in test: #{t.execute_class})"
		ensure
         @executed_tests += 1
		end
	}
	tFinish = Time.now
	@execution_time = tFinish - tStart
	clean_exit
end

# -- total by exit status
def all_by_exit_status(status)
   a = Array.new
   each { |t|
      a << t if t.exit_status == status
   }
   return a
end

# -- what do we do on exit ?
def clean_exit
	tasks_passed
   tests_passed     = all_by_exit_status(@task_config['test_exit_status_passed'])
   tests_failed     = all_by_exit_status(@task_config['test_exit_status_failed'])
   tests_skipped    = all_by_exit_status(@task_config['test_exit_status_skipped'])
   testcases_total  = all_testcase_in_tests
   testcases_passed = all_passing_testcase_in_tests
   verifications    = all_verifications_in_tests
   verifications_passed = all_passed_verifications_in_tests
   
   @task_config.merge!({'execution_time' => @execution_time, 'tests_passed' => tests_passed, 'tests_failed' => tests_failed, 'tests_skipped' => tests_skipped, 'testcases_total' => testcases_total, 'testcases_passed' => testcases_passed, 'verifications' => verifications, 'verifications_passed' => verifications_passed})
   
	 
	 #Publisher.new(@task_config).publish_reports
   
	 
	 
	 puts("\n==> DONE\n\n")
   puts(":: [SESSION]\n")
   puts("      -- reports prepared: #{@task_config['reports_dir']}\n")
   puts("      -- execution time  : #{@execution_time.to_s} secs\n")
   puts("      -- tests executed  : #{@executed_tests.to_s}\n")
   puts("      -- tests passed    : #{tests_passed.length.to_s}\n")
   puts("      -- tests failed    : #{tests_failed.length.to_s}\n")
   puts("      -- tests skipped   : #{tests_skipped.length.to_s}\n")
   puts("      -- cases total     : #{testcases_total.to_s}\n")
   puts("      -- cases passed    : #{testcases_passed.to_s}\n")
   puts("      -- verifications   : #{verifications.to_s}\n")
   puts("      -- verify passed   : #{verifications_passed.to_s}\n")
   
   if @task_config['test_retry']
      puts("      -- tests re-tried  : #{@tests_retried_counter.to_s}\n")
   end
   if tests_failed.length > 0 || verifications_passed != verifications
      puts("\n\n==> STATUS: [ some tests failed - execution failed ]\n")
      exit(1)
   end
   exit(0)
end

#
# ::: Publisher [ creating report files ] :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#
class Publisher
   def initialize(test_data)
      @task_config = test_data
      @tests_total     = @task_config['tests_passed'].length + @task_config['tests_failed'].length + @task_config['tests_skipped'].length
   end

   def write_file(file, data)
      File.open(file, 'w') {|f| f.write(data) }
   end

   def create_html_reports(status)
      output  = "<html><body>\n\nTests that #{status}:<br><br><table><tr><td>test</td><td>time</td></tr><tr></tr>\n"
      @task_config[status].each { |t|
         output += "<tr><td><a href='#{t.execute_class}.html'>#{t.execute_class}</a></td><td>#{t.execution_time}</td></tr>\n"
      }
      output += "</table></body></html>"
      write_file(@task_config['reports_dir'] + "/#{status}.html", output)
   end

   def publish_reports
      # -- remove reports dir if it exists, then create it
	  
      # -- create an xml file
      document  = "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n"
      document += "<testsuites>\n"
      document += "   <testsuite successes='#{@task_config['tests_passed'].length}'"
      document += "   skipped='#{@task_config['tests_skipped'].length}' failures='#{@task_config['tests_failed'].length}'"
      document += "   time='#{@task_config['execution_time']}' name='FunctionalTestSuite' tests='#{@tests_total}' subtests='#{@task_config['testcases_total'].to_s}'>\n"
      if @task_config['tests_passed'].length > 0
         @task_config['tests_passed'].each  { |t|
            document += "   <testcase name='#{t.execute_class}' classname='#{@task_config['xml_report_class_name']}' time='#{t.execution_time}'>\n"
            document += "      <passed message='Test Passed'><![CDATA[\n\n#{t.output}\n\n]]>\n       </passed>\n"
            document += "   </testcase>\n"
         }
      end
      if @task_config['tests_failed'].length > 0
         @task_config['tests_failed'].each  { |t|
            document += "   <testcase name='#{t.execute_class}' classname='#{@task_config['xml_report_class_name']}' time='#{t.execution_time}'>\n"
            document += "      <error message='Test Failed'><![CDATA[\n\n#{t.output}\n\n]]>\n       </error>\n"
            document += "   </testcase>\n"
         }
      end
      if @task_config['tests_skipped'].length > 0
         @task_config['tests_skipped'].each  { |t|
            document += "   <testcase name='#{t.execute_class}' classname='#{@task_config['xml_report_class_name']}' time='#{t.execution_time}'>\n"
            document += "      <skipped message='Test Skipped'><![CDATA[\n\n#{t.output}\n\n]]>\n       </skipped>\n"
            document += "   </testcase>\n"
         }
      end
      document += "   </testsuite>\n"
      document += "</testsuites>\n"
      # -- write XML report
      write_file(@task_config['reports_dir'] + "/" + @task_config['xml_report_file_name'], document)
	  
      # -- write HTML report
      totals  = "<html><body>\n\nTests: #{@tests_total.to_s}<br>\n"
      totals += "Tests Passed: <a href='tests_passed.html'>#{@task_config['tests_passed'].length.to_s}</a><br>\n"
      totals += "Tests Failed: <a href='tests_failed.html'>#{@task_config['tests_failed'].length.to_s}</a><br>\n"
      totals += "Tests Skipped: <a href='tests_skipped.html'>#{@task_config['tests_skipped'].length.to_s}</a><br>\n"
      totals += "Testcases: #{@task_config['testcases_total'].to_s}<br>\n"
      totals += "Testcases Passed: #{@task_config['testcases_passed'].to_s}<br>\n"
      totals += "Execution time: #{@task_config['execution_time']}<br>\n</body></html>"
      write_file(@task_config['reports_dir'] + "/report.html", totals)
      # -- create individual html report files complete with test output
      create_html_reports("tests_passed")
      create_html_reports("tests_failed")
      create_html_reports("tests_skipped")
	  
	  # -- write an additional XML file that can be used by jenkins to plot the number of tests (total number of tests, ie:total subtests)
	  #<report>
	  #	<serie1>10</serie1>
	  #	<serie2>20</serie2>
	  #	<serie3>30</serie3>
	  #</report>

	  document  = "<webtester_plot>\n"
	  document += "<testcases>#{@task_config['testcases_total'].to_s}</testcases>\n"	  
	  document += "<t_passed>#{@task_config['testcases_passed'].to_s}</t_passed>\n"	  
	  document += "<verifications>#{@task_config['verifications'].to_s}</verifications>\n"
	  document += "<v_passed>#{@task_config['verifications_passed'].to_s}</v_passed>\n"
	  document += "</webtester_plot>\n"
	  write_file(@task_config['reports_dir'] + "/" + @task_config['xml_plot_file_name'], document)
   end
end

def enforce_strict_task_definitions(task_type, options_hash)	
	options_hash.each do |key, value|
		optional = definition_hash[task_type.to_sym].split(',').keep_if { |v| v =~ /^(#).*/ }
		mandatory = definition_hash[task_type.to_sym].split(',').keep_if { |v| v =~ /^([^#]).*/ }
		
		mandatory.each do |mkey| 
			if !mandatory.any? { |w| mkey =~ /#{w}/ }
				raise "mandatory key: #{mkey} was not found in the list:" + mandatory
			end
		end
	end
end

class YamlReader
	def initialize(file)
		if File.exist?(file)
			return YAML::load(File.read(file))
		else
			raise "-- ERROR: config YAML file doesn't exist: " + file
		end
	end
	
	def show
		puts @CONFIG.inspect
	end
end

class TaskChain
	attr_accessor :die	
	def initialize
		@current_chain = 0
		@die = false
		@taskchain_array = Array.new
		@transpose_array = Array.new
	end
	
	def set_chainname(chainname)
		puts "chainname: #{chainname}"
		@chainname = chainname
	end
	
	def add_task(task_name, task_hash)
		if (task_hash["toolbox"] == "wrtest")
			task = WRTest.new(task_name, task_hash)
			@taskchain_array.push(task)
		elsif (task_hash["toolbox"] == "ruby")
			puts "no task defined : ruby"
		elsif (task_hash["toolbox"] == "cmdline")
			puts "no task defined : cmdline"
		end
	end
	
	def add_transpose(task_name, task_hash)
		puts "add transpose"
		if (task_hash["toolbox"] == "wrtest")
			@transpose_array.push(RubyTask.new(task_name, task_hash))
		end
	end
	
	def apply_operational()
		# determine what happens based on all task information we have
		puts "-Task(#{}) exit_status: "+ @taskchain_array[@current_chain].exit_status
		puts "-output: "+ @taskchain_array[@current_chain].output
		put "DETERMINING WHAT TO DO FOR OPERATIONAL"
		puts "-- nothing"
		
		@current_chain = @current_chain+1
	end
	
	def execute_current_task		
		@taskchain_array[@current_chain].execute
		apply_operational()
		
		if (@current_chain >= @taskchain_array.length) 
			@die = true
		end
	end	
end

class BaseTask
	#attr_accessor :path, :execute_class, :execute_args, :keywords, :description, :author, :testcase_headers,
	#             :exit_status, :output, :execution_time, :test_data, :verification_error_count, :verification_count
	def initialize(taskname, options = {})
		
		@taskname 			= taskname
		@toolbox 				= options["toolbox"]#options[:toolbox].nil ? raise 'toolbox mandatory for task: ' + task : options[:toolbox]
		@failover 			= options["failover"]
		#@tries 					= options["tries"].nil? ? 1 : options["tries"]
		@retry					= options['retry']
		@transpose			= options["transpose"]
		@exit_status 		= options["simulated_result"].nil? ? -1 : options["simulated_result"]
		@output					= ""
		@tStart					= Time.new()
		@tEnd						= Time.new()
		
		@transpose_count = 0
		@skipped_count = 0
		@exection_count = 0
		
		@execute_args   = options['execute_args']
		 
		@is_running = false
		@task_config      = test_data
		@execution_time = 0.0
		@timeout        = 144000 											# seconds (144000 is 4 hours)
		
		@report = @matrix = ""
	end

	# -- we should do something useful here
	# defined in the subclass
	def is_valid
	end	
	def task_cmdexec
	end

	def execute_task
		if is_valid
			# -- run the test if its valid
			# -- run also sets the output string
			#		
			run
			# -- write entire test output into its own log file
			#write_log
		else
			# -- skipping this test
			@exit_status = @task_config['test_exit_status_skipped']
		end
	end

	def write_file(file, data)
		File.open(file, 'w') {|f| f.write(data) }
	end

	def write_log
		d = /^(.*\/).*/.match(@execute_class)[1]
		FileUtils.mkdir_p(@task_config['reports_dir'] + "/#{d}")	   
		write_file(@task_config['reports_dir'] + "/#{@execute_class}.html", "<html><body><pre>" + @output + "</pre><pre>:: [Total SubTests]: " + @testcase_headers.length.to_s + "</br>:: [TestCases]</br>---> " + @testcase_headers.join("</br>---> ") + "</pre></body></html>")
	end
	

	def run
	end

	def to_s
		s = "\n  path:          " + @path              + "\n"
		if @author != nil
			 s += "  author         " + @author           + "\n"
		end
		s += "  execute_class  " + @execute_class       + "\n"
		s += "  execute_args   " + @execute_args        + "\n"
		s += "  keywords       " + @keywords.join(',')  + "\n"
		s += "  description    " + @description         + "\n"
		s += "  testcases:     " + @testcase_hash
		return s
	end
end
	 
class WRTest < BaseTask
	def initialize(taskname, options = {})
		enforce_strict_task_definitions(self.class.name, options)
		@pattern = options["pattern"]
		@keyword = options["keyword"]
		@directory = options["directory"]		
		super(taskname, options)
	end
	
	def run
		# I HAVE TO DEFINE WHAT LOG THIS OUTPUT GOES TO FOR REFERENCE LATER
		# ALSO, CREATE A MEGA LOG FILE WITH ALL OUTPUT
		@tStart = Time.now
		print("-- #{@tStart.strftime('[%H:%M:%S]')} running: [#{@taskname}] ")
		
		begin
			status = Timeout::timeout(@timeout.to_i) {
				@output = task_cmdexec
				#@output = "HERE IS THE LOG FROM WRTest SUCCESS"
				#@output      = `ruby #{@cmd} 2>&1`
				
				@exit_status = case @output
					when /PASSED/ then @task_config['test_exit_status_passed']
					when /FAILED/ then @task_config['test_exit_status_failed']
					else @task_config['test_exit_status_failed']
				end		
					# Gather all headers
				#@output.scan(/^-- {TESTCASE} \[(.*?)]/).each { |z| @testcase_headers << z[@task_config['test_heading_tag'].length+1..-1] }	
				#@output.scan(/^-- \{TESTCASE\} \[(.*?)\]/).each { |z| @testcase_headers << z }	
				# Gather verification error count
				#@verification_count = @output.scan(/^-- VERIFICATIONS EXECUTED: \((.*)\)/).to_s.to_i
				#@verification_error_count = @output.scan(/^-- VERIFICATION ERRORS: \((.*)\)/).to_s.to_i if @exit_status == @task_config['test_exit_status_failed']
			}
		rescue Timeout::Error => e
			@output << "\n\n[ TOTAL TEST TIME EXCEEDED ALLOWED DURATION AND WAS FORCED TO TERMINATE (#{@timeout.to_s}) ]"
			@exit_status = @task_config['test_exit_status_failed']
		ensure
			puts @exit_status
			puts "[++++++](OUTPUT INFORMATION):" if @task_config['output_on']
			puts @output if @task_config['output_on']
			puts "[------](OUTPUT)" if @task_config['output_on']
			puts "[++++++](TESTCASE INFORMATION):" if @task_config['output_on']
			puts @testcase_headers.join("\n") if @task_config['output_on']
			puts "[------](TESTCASE)" if @task_config['output_on']
		end
		
		@tEnd = Time.now
		#@execution_time = @tEnd - @tStart		
	end
	
	def is_valid
		puts "RakeTask is valid, i checked"
	end
	
	def to_s
		super
		puts "RakeTask:"
		puts "-> pattern: #{@pattern}"
		puts "-> keyword: #{@keyword}"
		puts "-> directory: #{@directory}"
	end
end